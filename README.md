# ğŸ’³ Credit Card Scraper with CrewAI + Gemini Flash 2.0

This project is a smart and scalable **credit card scraping tool** that uses **Selenium** for web automation and **Gemini Flash 2.0** (via Google AI) for intelligent content parsing. It leverages **CrewAI agents** to extract structured credit card data from web pages in a flexible, extensible architecture.

---

## ğŸ“ Project Structure

```
CREDIT_CARD_SCRAPER/
â”œâ”€â”€ Backend/
â”‚   â””â”€â”€ app.py                # Flask server to serve frontend
â”œâ”€â”€ Frontend/
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ script.js
â”‚   â”‚   â””â”€â”€ style.css
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html              # Web UI
â”œâ”€â”€ GeminiCreditCardAgent/
â”‚   â”œâ”€â”€ agents.py
â”‚   â”œâ”€â”€ crew.py
â”‚   â”œâ”€â”€ tasks.py
â”‚   â””â”€â”€ tools.py                   # CrewAI logic
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ credit_card_links.py
â”‚   â”œâ”€â”€ data_pre_process.py
â”‚   â””â”€â”€ scrape_format.py          # scraping instruction for agent
â”œâ”€â”€ .env                           # Store your Gemini API key here
â”œâ”€â”€ run.py                         # Main entry point
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Features

- ğŸ” Scrapes credit card listings from dynamic sites (e.g., SBI)
- ğŸ¤– Uses **Gemini Flash 2.0** agent for parsing content
- ğŸ§  Built with **CrewAI** agents and tools
- ğŸ› ï¸ Preprocesses scraped data with regex
- ğŸŒ Simple Flask-based web frontend
- ğŸ“¥ Download extracted data as a CSV file

---

## âš™ï¸ Setup Instructions

### 1. ğŸ—ï¸ Get Your Gemini API Key

- Go to [Google AI Studio](https://aistudio.google.com/apikey)
- Create or log into your account
- Generate an **API key**
- Copy the key and add it to your `.env` file in the root directory:

```env
GEMINI_API_KEY=your_key_here
```

---

### 2. ğŸ’» Clone the Repository

```bash
git clone https://github.com/AnurupaK/Credit-Card-Scrape-Agent.git
cd Credit-Card-Scrape-Agent
```

---

### 3. ğŸ Set Up Python Virtual Environment

```bash
python -m venv venv
# Activate on Windows:
venv\Scripts\activate
# Or on macOS/Linux:
source venv/bin/activate
```

---

### 4. ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

Make sure you have **Google Chrome** and the appropriate **ChromeDriver** installed and accessible in your PATH.

---

### 5. ğŸ”§ Run the Application

```bash
python run.py
```

Then open your browser and navigate to:

```
http://localhost:5000
```

---

## ğŸŒ Supported Websites

Currently supports scraping from:

- [SBI Credit Cards](https://www.sbicard.com/en/personal/credit-cards.page)

---

## ğŸ§  How It Works

1. **Selenium** automates visiting each credit card URL and collects the `outerHTML`.
2. This raw HTML is passed to **Gemini Flash 2.0** via CrewAI agent for interpretation.
3. The agent returns a **JSON structure** representing credit card data.
4. The data is cleaned using **regex-based preprocessing**.
5. The frontend allows users to trigger and visualize scraping results.

---

## ğŸ› ï¸ How to Use the App

The web app provides an interactive interface to control and monitor the scraping process.

### ğŸ”˜ UI Components

- **URL Box**: Paste the listing page URL (e.g., SBI credit cards)
- **Batch Size Box**: Set number of links to process at once
- **Buttons**:
  - `Start`: Begins scraping
  - `Next`: Processes the next batch
  - `Download CSV`: Exports current scraped data
- **Output Screen**: Displays parsed credit card info
- **Status Area**: Shows progress (e.g., `Fetching...`)

---

### ğŸ§© Flow of Operation

```
ğŸ”¹ STEP 1: Input Details
   â””â”€ ğŸ“¥ Enter the **URL** of the credit card listing page
   â””â”€ ğŸ”¢ Specify the **Batch Size** (number of links to process at a time)

            â¬‡ï¸

ğŸ”¹ STEP 2: Start Scraping
   â””â”€ â–¶ï¸ Click the **"Start"** button
   â””â”€ â³ Status shows **"Fetching..."**
   â””â”€ ğŸ–¥ï¸ Scraped credit card data appears in the **Output Screen**

            â¬‡ï¸

ğŸ”¹ STEP 3: (Optional) Scrape More
   â””â”€ ğŸ” Click the **"Next"** button to process the next batch of links
   â””â”€ â³ Status shows **"Fetching..."**
   â””â”€ â• New batch of scraped data is added to the output

            â¬‡ï¸

ğŸ”¹ STEP 4: Download Data
   â””â”€ ğŸ’¾ Click **"Download CSV"** to export current data
   â””â”€ ğŸ“Œ Can be done:
         - After **Start**
         - After any **Next**
         - Or after scraping **all batches**

âœ… **Flexible Downloading**: You can export data anytimeâ€”no need to wait until the end.
```

---

